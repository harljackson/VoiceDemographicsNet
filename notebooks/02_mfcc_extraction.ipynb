{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e2ba2c",
   "metadata": {},
   "source": [
    "# MFCC Feature Extraction\n",
    "\n",
    "This notebook extracts Mel-Frequency Cepstral Coefficients (MFCCs) from the selected audio samples to create a numerical feature representation suitable for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7c2d1",
   "metadata": {},
   "source": [
    "# Install Required Libraries\n",
    "\n",
    "Installs librosa for audio processing, pandas for data manipulation, and numpy for numerical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec662fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install librosa, pandas, and numpy for audio processing and data manipulation\n",
    "%pip install librosa pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for audio processing and data manipulation\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72076de",
   "metadata": {},
   "source": [
    "# Load Filtered Dataset\n",
    "\n",
    "This cell loads the previously created 1000-sample dataset subset from disk and displays the first few rows to verify successful loading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc102dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subset metadata\n",
    "subset_path = r\"D:/mcv-scripted-en-v23.0/cv-corpus-23.0-2025-09-05/en/subset_1000.csv\"\n",
    "df_small = pd.read_csv(subset_path)\n",
    "\n",
    "# Display start of data\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a941eb",
   "metadata": {},
   "source": [
    "# Inspect Gender Labels\n",
    "\n",
    "This cell displays the values in the gender column to identify available label categories and check for inconsistencies or missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a73a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values in the \"gender\" column\n",
    "df_small[\"gender\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03921fd",
   "metadata": {},
   "source": [
    "# Define MFCC Extraction Function\n",
    "\n",
    "This cell defines a helper function that loads an audio file, extracts MFCC features, and returns a fixed-length feature vector by averaging time frames. Basic error handling is also implemented to skip files that cannot be processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MFCC features from an audio file\n",
    "def extract_mfcc(audio_path, n_mfcc=13):\n",
    "    try:\n",
    "        # Load audio file and extract MFCC features\n",
    "        signal, sr = librosa.load(audio_path, sr=22050) # Standardize sample rate\n",
    "        mfcc_result = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc) # Extract MFCCs from audio\n",
    "        mfcc_mean = np.mean(mfcc_result, axis=1) # Compute mean MFCCs across time frames\n",
    "        # Return MFCC features\n",
    "        return mfcc_mean \n",
    "    # Handle exceptions during audio processing and return None if an error occurs\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b030731",
   "metadata": {},
   "source": [
    "# Define Pitch Feature Extraction Function\n",
    "\n",
    "This cell defines a function that extracts basic pitch statistics from an audio file using fundamental frequency estimation. Unvoiced frames are removed, and summary statistics are returned as a fixed length feature vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pitch_features(audio_path, sr=16000):\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "\n",
    "    # Extract pitch features - adjusted fmin/fmax for broader range\n",
    "    f0 = librosa.yin(y, fmin=50, fmax=400, sr=sr)  # Increased fmax to 400\n",
    "\n",
    "    # Remove unvoiced frames\n",
    "    f0 = f0[~np.isnan(f0)]\n",
    "\n",
    "    # If no pitch is detected, return zeros\n",
    "    if len(f0) == 0:\n",
    "        return [0, 0, 0, 0, 0]\n",
    "    \n",
    "    # Return pitch features\n",
    "    return [\n",
    "        np.mean(f0),        # Average pitch\n",
    "        np.std(f0),         # Pitch variation\n",
    "        np.min(f0),         # Lowest pitch\n",
    "        np.max(f0),         # Highest pitch\n",
    "        np.median(f0)       # Median pitch \n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f38834",
   "metadata": {},
   "source": [
    "# Extract Combined Audio Features\n",
    "\n",
    "This cell iterates through the dataset subset and extracts MFCC and pitch features for each audio. The extracted features are combined with age, gender, and sentence identifiers and stored for further processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfefb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MFCCs AND pitch features for all samples in the subset\n",
    "mfcc_features = [] #\n",
    "\n",
    "# Iterate through each row in the DataFrame and extract features\n",
    "for i, row in df_small.iterrows():\n",
    "    # Get the audio file path from the DataFrame\n",
    "    audio_file = row[\"audio_path\"] \n",
    "\n",
    "    # Extract MFCC features using the defined function\n",
    "    mfcc_feats = extract_mfcc(audio_file)\n",
    "    \n",
    "    # Extract pitch features\n",
    "    pitch_feats = extract_pitch_features(audio_file)\n",
    "\n",
    "    # Ensures that only valid features are appended to the list\n",
    "    if mfcc_feats is not None:\n",
    "        mfcc_features.append([\n",
    "            *mfcc_feats,    \n",
    "            *pitch_feats,     \n",
    "            row[\"age\"],\n",
    "            row[\"gender\"],\n",
    "            row[\"sentence_id\"]\n",
    "        ])\n",
    "\n",
    "# Display the number of successfully extracted feature sets\n",
    "print(f\"Extracted features for {len(mfcc_features)} samples\")\n",
    "print(f\"Feature vector size: {len(mfcc_features[0]) - 3} (excluding age, gender, sentence_id)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60171914",
   "metadata": {},
   "source": [
    "# Construct Feature DataFrame\n",
    "\n",
    "This cell organises the extracted MFCC and pitch features into a structured DataFrame with labelled columns and displays the first few rows for verification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62086f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the extracted features\n",
    "columns = (\n",
    "    [f\"mfcc_{i}\" for i in range(14)] +\n",
    "    [\"pitch_mean\", \"pitch_std\", \"pitch_min\", \"pitch_max\"] +\n",
    "    [\"age\", \"gender\", \"sentence_id\"]\n",
    ")\n",
    "\n",
    "# Create a DataFrame with the extracted features\n",
    "df_features = pd.DataFrame(mfcc_features, columns=columns)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ed0e4e",
   "metadata": {},
   "source": [
    "# Save Extracted Features\n",
    "\n",
    "This cell saves the extracted audio feature dataset to a CSV file for use in subsequent model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b156f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the extracted MFCC features to a CSV file\n",
    "df_features.to_csv(\"D:/mcv-scripted-en-v23.0/cv-corpus-23.0-2025-09-05/features.csv\", index=False)\n",
    "print(\"SAVED :D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394b96b",
   "metadata": {},
   "source": [
    "# Prepare Feature Arrays and Labels\n",
    "\n",
    "This cell converts the extracted feature data into NumPy arrays, separates input features from gender and age labels, perform basic sanity checks, and saves the arrays for use in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4184e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy and separate features from labels\n",
    "mfcc_features = np.array(mfcc_features, dtype=object)\n",
    "X = np.array([row[:-3] for row in mfcc_features], dtype=float)\n",
    "y_gender = np.array([row[-2] for row in mfcc_features])\n",
    "y_age = np.array([row[-3] for row in mfcc_features])\n",
    "\n",
    "print(f\"Feature matrix shape BEFORE saving: {X.shape}\")  # Should be (1000, 18)\n",
    "\n",
    "# Check that pitch is there\n",
    "print(f\"First sample last 5 features (pitch): {X[0, -5:]}\")\n",
    "\n",
    "# Save the NEW features\n",
    "np.save('X_features.npy', X)\n",
    "np.save('y_gender.npy', y_gender)\n",
    "np.save('y_age.npy', y_age)\n",
    "\n",
    "print(\"\\nâœ“ Features with pitch saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
